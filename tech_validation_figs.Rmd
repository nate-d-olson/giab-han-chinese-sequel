---
title: "Technical Validation"
author: "Nate Olson"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```


```{r}
calc_n50 <- function(read_length_df){
    cum_length_df <- read_length_df %>% 
        arrange(read_length) %>% 
        mutate(total_length = as.numeric(read_length * count),
               cum_length = cumsum(total_length))

    with(cum_length_df, min(read_length[cum_length >= max(cum_length)*0.5]))
}
```

```{r}
read_length_df <- list.files("data", pattern = "stats_read_length",full.names = TRUE) %>% 
    set_names(str_extract(., "HG00.")) %>% 
    map_dfr(read_tsv, col_names = c("read_length", "count"), .id = "hgref")
```

## Coverage Figure
```{r}
coverage_df <- read_length_df %>% 
    group_by(hgref) %>% 
    mutate(coverage = read_length * count / 3.1e9) %>% 
    arrange(-read_length) %>% 
    mutate(cum_coverage = cumsum(coverage))
```

```{r}
ggplot(coverage_df) + 
        geom_path(aes(x = read_length/1000, y = cum_coverage)) + 
        labs(x = "Read Length (Kb)", y = "Coverage by Reads > Length") + 
        theme_bw() + 
    facet_wrap(~hgref) + 
    xlim(0,50)
```

## Coverage summary table
```{r}
coverage_df %>% group_by(hgref) %>% 
    mutate(total_coverage = max(cum_coverage),
           max_read_length = max(read_length)) %>% 
    group_by(hgref, total_coverage, max_read_length) %>% 
    nest() %>% 
    mutate(n50 = map_dbl(data, calc_n50)) %>% 
    select(-data)
```

## Read length distribution 
Raw read lengths - use mapped read length distribution figure instead
```{r}
read_len_dist_plot <- read_length_df %>% 
    mutate(read_length_kb = round(read_length/1000, 0)) %>% 
    group_by(hgref, read_length_kb) %>% 
    summarise(count = sum(count))

read_len_singletons <- read_len_dist_plot %>% filter(count == 1)

ggplot(read_len_dist_plot) + 
    geom_bar(aes(x = read_length_kb, y = count), stat = "identity") + 
    geom_rug(data = read_len_singletons, aes(x  = read_length_kb)) +
    facet_wrap(~hgref) + 
    theme_bw() + 
    scale_y_log10() + annotation_logticks(sides = "l") + 
    labs(x = "Read Length (kb)", y = "Number of Reads")
```

```{r}
read_length_df %>% filter(read_length > 100000) %>% 
    group_by(hgref) %>% 
    summarise(n_gt100kb = sum(count))
```

```{r}
read_length_df %>% 
    group_by(hgref) %>% 
    summarise(mean_length = weighted.mean(read_length, count))
```


## Summary stats table
```{r}
summary_stats_df <- list.files("data", pattern = "stats_summary", full.names = TRUE) %>% 
    set_names(str_extract(., "HG00.")) %>% 
    map_dfr(read_delim, delim = ":", 
            col_names = c("Key", "Value"), .id = "hgref") %>% 
    mutate(Value = str_remove(Value, "\t#.*"),
           Value = as.numeric(str_remove(Value, "\t")))
```

```{r}
summary_stats_df %>% 
    filter(Key %in% c("sequences","reads mapped","reads MQ0", "error rate")) %>% 
    spread(Key, Value) %>% 
    mutate(mapping_rate = `reads mapped`/sequences,
           MQ0_rate = `reads MQ0`/ `reads mapped`) %>% 
    select(-`reads mapped`)
```



## Coverage Distribution
```{r}
genome_cov_df <- list.files("data", pattern = "stats_cov", full.names = TRUE) %>% 
    set_names(str_extract(., "HG00.")) %>% 
    map_dfr(read_tsv, col_names = c("coverage_bin", "coverage_max", "nbases"), .id = "hgref")
```

```{r}
genome_cov_df %>% 
    filter(nbases > 1e7 | coverage_max < 40) %>% 
    ggplot() + 
    geom_path(aes(x = coverage_max, y = nbases/1000000, color = hgref)) + 
    # facet_wrap(~hgref, ncol = 1, scales = "free_y") + 
    theme_bw() + 
    labs(x = "Coverage", y = "Mb", color = "NIST ID")
```

## Long Read Check
Verification of reads with read lengths longer than expected based on sequencing method. 
Comment from Aaron Wenger - "For 10hr movies, I would expect that the maximum read lengths are around 72 kb (2 basepairs / second * 10 hrs * 3600 seconds / hr)."
```{r}
hg005_bam_stats <- read_tsv("data/HG005_PacBio_GRCh37.bam.stats.tsv.gz")
hg005_bam_stats %>% filter(bases > 100000)
```

```{r}
hg006_bam_stats <- read_tsv("data/HG006_PacBio_GRCh37.bam.stats.tsv.gz")
hg006_bam_stats %>% filter(bases > 100000)
```


```{r}
hg007_bam_stats <- read_tsv("data/HG007_PacBio_GRCh37.bam.stats.tsv.gz")
hg007_bam_stats %>% filter(bases > 70000)
```


## Alignment Stats
```{r}
aln_stat_files <- list.files("data", 
                     pattern = "bam.stats.tsv.gz", full.names = TRUE,
                     recursive = TRUE)

# BAM statistics combined bam stat files
col_names <- c("read_id", 
               "aln_lengthsum", 
               "aln_lengthmax",
               "aln_count",
               "ref_lengthsum",
               "ref_lengthmax",
               "ref_lengthcount",
               "bases")

aln_names <- str_extract(aln_stat_files, "(?<=data/).*(?=_PacBio_GRCh37)")
aln_stat_df <- aln_stat_files %>%  
    set_names(aln_names) %>% 
    map_dfr(read_tsv, 
            .id = "Run")

```


Extracting reads from bams using `bamtools filter -length 70000 -in [IN BAM] -out [OUT BAM]` to get read alignments. 
No reads were output.
Using picard `FilterSamReads`

Writing read ids to file to filter bams.
```{r}
aln_stat_df %>% filter(bases > 70000, Run == "HG005") %>% 
    select(read_id) %>% 
    write_tsv("data/HG005_read_id_gt70k.tsv")
```

```{r}
aln_stat_df %>% filter(bases > 70000, Run == "HG006") %>% 
    select(read_id) %>% 
    write_tsv("data/HG006_read_id_gt70k.tsv")

```

```{r}
aln_stat_df %>% filter(bases > 70000, Run == "HG007") %>% 
    select(read_id) %>% 
    write_tsv("data/HG007_read_id_gt70k.tsv")
```

Genome Total Coverage Max Read Length N50
```{r}
calc_n50 <- function(seq_lengths){
    sorted_lengths <- sort(seq_lengths)
    cum_lengths <- cumsum(sorted_lengths)
    min(sorted_lengths[cum_lengths >= max(cum_lengths)*0.5])
}

aln_summary_stats_df <- aln_stat_df %>% 
    mutate(aln_lengthmax = as.numeric(aln_lengthmax)) %>% 
    group_by(Run) %>% 
    summarise(N50 = calc_n50(aln_lengthmax),
              max_read = max(aln_lengthmax),
           throughput = sum(aln_lengthmax))
aln_summary_stats_df
```

## Alignment Based Figures
```{r}
cov_breaks <- c(1:75) * 1000
cov_df <- aln_stat_df %>% 
    mutate(length_bins = cut(aln_lengthmax, 
                             breaks = c(cov_breaks, max(.$aln_lengthmax)),
                             labels = cov_breaks)) %>%
    group_by(Run, length_bins) %>% 
    summarise(coverage = sum(as.numeric(aln_lengthmax))/3.1e9, 
              n_reads = n()) %>% 
    group_by(Run) %>% 
    arrange(desc(length_bins)) %>% 
    mutate(cum_coverage = cumsum(coverage)) %>% 
    mutate(length_bins = as.numeric(as.character(length_bins)))
```

## Coverage Figure
```{r}
ggplot(cov_df) + 
    geom_path(aes(x = length_bins/1000, y = cum_coverage, color = Run)) +
    # facet_wrap(~Run) + 
    theme_bw() + 
    labs(x = "Read Length (Kb)", y = "Coverage by Reads > length", color = "NIST ID")
```

## Read length
```{r}
cov_df %>% ungroup() %>% 
    ggplot() + 
    geom_bar(aes(x = length_bins/1000, y = n_reads), stat = "identity") + 
    facet_wrap(~Run, ncol = 1) + 
    theme_bw() +
    # scale_y_log10() + annotation_logticks(sides = "l") + 
    labs(x = "Read Length (kb)", y = "Number of Reads")
```

```{r}
cov_df %>% ungroup() %>% 
    ggplot() + 
    geom_boxplot(aes(x = Run, y = length_bins/1000, fill = Run)) + 
    # facet_wrap(~Run, ncol = 1) + 
    theme_bw() +
    # scale_y_log10() + annotation_logticks(sides = "l") + 
    labs(x = "NIST Sample ID", y = "Mapped Read Length (kb)") + 
    theme(legend.position = "none")
```

